\documentclass[10pt,oneside,a4paper]{article}
\usepackage{setspace}
\doublespacing
\usepackage[left=1.5in, right=1in, top=1in, bottom=1in]{geometry}
\usepackage{graphicx} %TO include graphics in document
\usepackage{amssymb}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{cite}
\usepackage{url}

\author{Arpit Gawande}
\title{DDoS Detection and Defense Using Learning Tool}
\date{\today}
\begin{document}

\begin{abstract}
Distributed Denial of Service (DDoS) attacks are common these days\cite{ddosattacknews}. So it is evident that current industry solutions such as completely relying on Internet Service Provider(ISP) or setting up DDoS defense infrastructure are not sufficient in detecting and mitigating DDoS attacks, hence consistent research is needed. Most of the current industry solutions involve setting up centralized expensive hardware system which can analyze the packets\footnote{Messages that are sent on Internet are broken into shorter messages for transmission. These short messages are called packets. Term coined by Donald Watts Davies.} \cite{networkdatapacket} for probable DDoS attacks. Also each router provider has different protocols to communicate the between the DDoS attack detection system and the router limiting the reach of DDoS detection systems. In this paper we are going to discuss a way to detect and mitigate DDoS attack using machine learning tools also we will discuss how can we have open architecture to communicate attack information with different network devices.
\end{abstract}

\section{Existing Systems}

Distributed Denial of Service (DDoS) attack is the way to jam host network or its resources with large number of data packets, so that host become disabled to serve. There are different types of DDoS attacks such as
1. Volume based e.g. SYN Flood Attacks, in which victim is flooded with hight volume of packets or connection.
2. Application based, in which application such as DNS, VOIP or HTTP where attacked.
3. Low rate DDoS attacks, in which attacker exploit the vulnerability in application design, e.g. Slowloris.
\cite{DDoSAttacks}

The real challenge in detecting and defending DDoS attack is because of its dynamic nature. The source\footnote{It is a system/device on the Internet which has an IP address and which is involved in DDoS attack} is not a single node or system on the Internet but there can be many systems participating in DDoS attack, and often these systems are distributed over different regions of the Internet. Also the source of the packet is often spoofed\footnote{spoofing is the way to change the source IP address of the message. This is a known issue in the protocol iteself not in the implementation}\cite{ipspoofing}, which makes more harder to know the actual IP address of system from where attack is originated because they hide original attack source. On top of that, many times the source system itself is not aware that it is compromised and it is being used as bot\cite{bot} by attacker to launch DDoS attack.

Detecting and mitigating attack at the destination\footnote{System under DDoS attack} is not very useful as because destination may know that the attack is happening but to stop it happening it will have to block all the incoming traffic including the legitimate traffic, because source address can not be reliable way to know the attack source. To avoid this, many network device producing companies such as Cisco, Netgear have come up with some solutions. Many of the solutions provided by those giant or the research that is done in this field has been focusing on collecting network traffic flow information\cite{networkTrafficFlow} (we would call it just flow) at routers(gateways) and then send that information to the central system for analysis. Central system is a hardware and software infrastructure which is capable of processing and analyzing large flow information.\par

Some of the major protocols which are widely used for flow collection and analysis are, Internet Protocol Flow Information Export (IPFIX) protocol created by Internet Engineering Task Force (IETF), Ciscos NetFlow\cite{cisconetflow} and Sflow(Sampled flow)\cite{sflow}. These protocols have defined standard way to export flow information from router and similar devices. All these flow monitoring protocols gather information and send the consolidated flow information to the centralized server where user can login and perform functions; such as Security Monitoring, Bandwidth monitoring, Resource Management, Traffic Analysis, Performance Management etc. It will have some modules which are specifically used for anomaly/DDoS detection.\par

E.g. Cisco netflow has flow exporter, collector and analysis modules. Flow exporter modules are installed on routers. The routers which are having flow exporter modules, send flow information to collector module installed on the server. Along with the collector module server also has analysis module which can be used to detect different patterns in the flow.\par

These technologies scales well and can be sufficient to indicate trends in network traffic but they have limitations. 1) They are not cross platform, e.g. router with Sflow protocol would not be able to work with Cisco routers. 2) They involve setting up expensive hardware which would act as collector server. 3) Source address is used for flow analysis which is not reliable due to IP spoofing in the case of of DDoS attack.\par

Now we know that router based flow analysis can be useful for anomaly detection but it has limitations. We don't want to set up expensive hardware, we want to have protocol or system which is compatible with other routers. Also we dont want source IP address for detection\footnote{Hence forth In our paper we would consider flow only in sense of destination address} analysis. So if we could come up with the way by which we could detect anomaly in the traffic at the routers independent of manufacturer, could create a protocol to communicate the attack parameters to allow routers to take decisions and if we only use destination IP address for analysis, then we would be more efficient in detecting and mitigating DDoS attacks.

\section{DDoS Detection and Mitigation}

One of the way to detect the DDoS attack is to check for anomalous behavior in the network traffic. This can be done at different points. Either at the destination server or at the router. Once the attack is detected by observing the behavior of the traffic to mitigate it, we would have to block all the packets which are causing the attack.

\section{Network Functioning}
A switch creates a network and router connects networks. A router links computers to the Internet through other routers. Routers are the backbone of the network who helps to forward packet from one point to other point on the Internet. Every packet traveling on Internet has to go through router\cite{swithcrouter}.Router knows where the packet is destine hence it could serve as first point of knowledge about the change in the flow information for a destine network. Each router has interfaces to which hosts or other network are connected. So router is aware to whom it is connected. Router uses protocol to communicate and by that they gather knowledge about other networks or router on the Internet. ICMP\cite{icmp} is one of the most frequently use protocol by routers to communicate.\par

\begin{figure}[H]
\centering
\includegraphics[width=0.80\textwidth]{Routers}
\caption{Network Example} \label{fig:routers}
\end{figure}


Lets illustrated this using an example. In the above figure we can see that host S1, S2, S3 are connected to router R1. Router R1 is connected to Internet through router R2, R3, R4 , thus every packet that would be reaching to S2 would come from either of these three routers. All three routers are locates at different geographical region. Most of the websites are regional, either county, state or national (If we leave out few global websites) and hence they are mostly accessed from those region it is meant for. E.g. Rutgers University website would be accessed mostly from the eastern region of United States and that too mostly from the New Jersey State or the Philadelphia region.\par
Using traceroute we can find out how many hope away the destination is. Each hope is the router on the Internet. Following is one of the captured traceroute for Rutgers University website.\par
%\vspace{5mm} % vertical space
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{TraceRoute}
\caption{Trace Route: All the routers in the path to destination} \label{fig:traceroute}
\end{figure}

We can see that there are about 14 routers (if we don't consider the home router 192.168.0.1) to reach to the camden.rutgers.edu. This trace route is taken from a location in the New Jersey State.\par


\section{Suggested Approach}

From Figure \ref{fig:routers} and \ref{fig:traceroute} we know that routers are located at different geographical locations and also there is pattern in which the particular destination website is getting accessed from the different regions. Some of the service providers such as  GeoIP or Google can find out the location from where the traffic is coming in the network for a given destination, but that is approximate based on the source IP, which in the case of DDoS attack is unreliable information because packet source address are often spoofed. So it could be difficult to know the actual geographical location from which packet has come. Only routers can provide the correct geographical information about the source of the packet.\par

In the normal scenario there would be some definite pattern in which the website is getting accessed from different regions and this pattern can be learned over the time. Thus finding this pattern in the flow at the router can form the basis of our analysis. Whenever there is deviation from the normal flow pattern learned in the past for a particular destination then that change in pattern as well as router geographical region information can be communicated to the destination network. Destination network on receiving that information can decide whether it want the reporting router to discard or forward the traffic for the destination. This is selective process in which traffic from only specified router is blocked while traffic from other routers remain unaffected\par

With the advance of electronic and the Internet of things, processing and storage capacity of the electronic devices has increased. Router are also not left behind, but storage capacity of router is always very less compared to storage server which collect flow data for network traffic analysis. If we use the learning techniques which don't need much storage then we don't have to store large chunk of packets on the router. Instead of storing data packets for longer time for analysis, we can learn from small number of packets and then discard packets once learning is done leaving behind only learned information on the router. This is necessary because the number of entries on the Internet routing table has steadily grown. Now that the table has passed 500,000 routes\cite{routingtablesize} so storing each and every flow information for these routes could be difficult.\par

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{RouterCommunication}
\caption{DDoS Attack path} \label{fig:attackpath}
\end{figure}


In the above figure attack initiated from the region where router R6 is located and from R6 data packets travel to victim\footnote{Victim is a computer system which is under DDoS attack} through router R3 and R1. If we can detect attack at router R6, then router R6 can discard all the packets packets heading towards S2. In this process only traffic from router R6 is affected but traffic from all other routers remain unaffected.

To achieve this, we would gather the flow information during a time window (e.g 300 sec) whose size would be fixed at the beginning.
These time windows can be combined to form a period which is a portion of a day during which traffic is measured. Once we have flow information we can apply learning techniques on each flow iteratively to gain deeper knowledge about normal behavior of the flow.\par

In the proposed system, each router will itself act as a analyzer. Each packet will be analyzed and flow statistic would be created based on the destination IP address. Based on the statistic we would cluster destination IP address using input feature vector. Clustering is the process of examining a collection of “points,” and grouping the points into “clusters” according to some distance measure.The goal is that
points in the same cluster have a small distance from one another, while points in different clusters are at a large distance from one another\cite{machineLearning}.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{Data_Flow_Capture}
\caption{Data Flow Segments} \label{fig:flow}
\end{figure}


Once cluster is learned it would be used as bench mark for all future flow. Router would constantly keep clustering destination IP address and if there is deviation in the normal traffic at router for a any destination then that would affect the clustering and would cause destination to be placed in different cluster. This change in clustering can be marked as change in the behavior of the traffic. Along with the cluster we would also use Novelty Detection algorithm to achieve more accurate result. This change in traffic pattern will be reported to destination network, which then decide on regulating the traffic to itself on the router which has send that information\par

\section{Implementation}

There are different types of DDoS attacks, such as Volume based, Application based and also Low rate DDoS attacks. Among which the volume based attacks are most common. In the volume base attack victim is flooded with high volume of Internet packets (TCP, UDP, HTTP or ICMP)

For the demonstration of our approach we will simulate volumed based Bot attack. Bots are the compromised computer systems, controlled by attacker for launching attack. They are not bounded by geographical boundaries so can be anywhere in the Internet. Botnet(Network  of bots) are employed by attackers to launch DDoS attack. As we know that Internet is connection of different computer system which can communicate with each other. This communication can occur through different channels such as cables, satellite or radio device and these communication channels run through out the glob; connecting different computer systems at different locations.

We are going to use Wireshark, an open source tool, for capturing Internet packet. Wireshark can capture all digital information received or send through devices such as Ethernet devices, which connects computer to the Internet. It also helps to segregate data in terms of packets pertaining different protocols (e.g. TCP, UDP).\par

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{Wireshark_Tools.png}
\caption{Wireshark Tool: snippet of captured packets} \label{fig:wireshark}
\end{figure}

To gather data for the demonstration we have created a small network with one router and we designated a host machine in that network as a target for the DDoS attack. We have also installed Wireshark on one of the system in the same network. For capturing traffic in the network we are using the Promiscuous mode in Wireshark. In Promiscuous mode, network interface can record not only the traffic that is intended to its self but all of the traffic on the network. This setup is similar to capturing traffic on a router connected to few host machines.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{demo_network}
\caption{Demo Network: for purpose of demonstration} \label{fig:demonetwork}
\end{figure}

Once we start Wireshark we did let it run for a while and then we orchestrate an attack on one of the host (e.g. 192.168.0.4 in Figure \ref{fig:demonetwork}) in the network from another host(e.g. 192.168.0.10 in Figure \ref{fig:demonetwork}) from the same network.

For the sake of simplicity we would be dealing with TCP and UPD flood attacks.

Attack is engineered using Low Orbit Ion Canon(LOIC, a free tool which is even used by attackers in the real world DDoS attacks. This tool allows us to launch TCP and UDP flood attack on any destination. In this paper we would be analyzing the flow based TCP and UDP attack, which is one of the most common type of DDoS attacks.
In the LOIC tool we need to give IP address and the port number of the destination where we want to orchestrate attack while rest of the work is done by it. This tool flood destination with packets and if we choose TCP then it will try to create multiple connections and send packets over them. We start flood attack on one of the system in our network (e.g. 192.168.0.7) and let it continue for few minuets. We launched such attacks few times in between our packet capturing session.

All the traffic including the normal and the attack traffic will get captured in the Wireshark. Packets are captured for about five hours in the given network. Once the packets are captured they are saved as pcapng file which is a Wireshark file format for captured packets. Captured packets during the normal operation and during the attacks are saved separately. The normal packet flow information is used for training and testing the learning algorithms while attack packets flow information would be used for detecting the attack (Which would be explained further in the paper). Wireshark capture every detail of the packets but we don't need all of the information, we would only be interested in the IP layer information of the packet. Most of the routers analyze IP layer of the packet for routing. Having said that there is no reason except than the performance that other layers of the packet are not analyzed.\par

To extract IP layer information from the captured packets data extraction program \textit{data\_extraction} is written in Python. This program would extract address, port and time information from each of the captured IP packets\footnote{packets containing IP information}. It will also divide the captured data into 300 seconds capture window thus creating a sample data which is collection of IP packets captured over the time of 300 seconds. It then write each sample in separate file for further processing. Every sample file represent a one flow information where flow is logically treated as the IP packets captured over 300 second time interval as explained before. This sampling of the packets in the form of flow is the continuous process. We will store the flow information in the form of sample files, we will train learning algorithms using those sample file, then those sample files will be discarded and new samples will be used for further training. This training process has to be continuous process in order to correctly reflect the current status of the flow at given router. What ever the new information learned is augmented with the previous learning to have the correct understanding of the flow.

This learning can be done for the time during the day or given day during the week of year. e.g. We can have separate learning information for flow from morning 9 am to 12 pm and also can have information for evening 6 pm to 12 pm.

\begin{table}[H]
\centering
  \begin{tabular}{| l | c | l | c |}
    \hline
    Destination IP Address      & Protocol  & Time stamp(Sec.)  & Sample Number \\
    \hline
    52.6.129.72         & 6         & 1512094785.928596000  & 1 \\ \hline
    192.168.0.4         & 6         & 1512094785.946987000  & 1 \\ \hline
    192.168.0.4         & 17        & 1512094786.148488000  & 1 \\ \hline
  \end{tabular}
\caption{Flow snippet} \label{table:flow-snippet}
\end{table}

The sample files created using the \textit{data\_extraction} program will be used to create the training set.

Flow based model is build as it is more reliable and fast. Packet analyzing is often difficult due to size and encryption. Also destination port number is not a reliable information in detecting attacks because of the fact that attacker use different ports during attack.

Creating training set is an intermediate step in which IP packet count for each destination for given protocol(e.g TCP, UDP) is calculated. The training set gives us the flow information for each destination (i.e. how many packets are recorded for a given destination IP address during a time window e.g. 300 seconds). We are using Python program to create training set from the sample files. Our training set look like following in which each row is one training example with destination IP address as label. A training example is $\mathbb{R}^3$ vector whose elements are the number of packets observed for a particular protocol during 300 second time.

\begin{table}[H]
\centering
  \begin{tabular}{| l | c | c | c |}
    \hline
    & \multicolumn{3}{ |c| }{IP Packet count} \\ \cline{2-4}
    {Destination IP Address}  &ICMP  &TCP &UDP\\
    \hline
    172.217.10.134  & 0     & 8     & 12 \\ \hline
    65.19.96.252    & 5     & 0     & 192 \\ \hline
    68.67.178.134   & 0     & 78    & 0 \\ \hline
  \end{tabular}
\caption{Training Set with three training examples} \label{table:feature}
\end{table}

We ran python program to convert each sample file to training set and testing sets. Each sample file has corresponding train/test set file. We store both train and test sets on the file systems so that they can be used for training and testing the algorithms.

There are around 150 protocols managed and assigned by Internet Assigned Numbers Authority (IANA) but most commonly used protocols in the DDoS attack are the ICMP, TCP and UDP protocols. For our training and analysis purpose we are using only these three protocols as the desired feature. In the larger system such as routers managed by ISP, other protocols can also be used as features if required.\par

\subsection{Machine Learning}

According to Tom Mitchell (1998) A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience.

A learning algorithm build the hypothesis using training set as input then that hypothesis is used to perform predictions. Most common categorization of machine learning algorithm is Supervised and Unsupervised.

Let $f$ be the function which we need to guess from input vector $X$ = \{$x^{1}$, $x^{2}$, ..., $x^{m}$\}. This $X$ also called as training set where $x's$ represent an input variable/feature vector and $m$ is number of feature vectors in the training set. Let $h$ be the hypothesis about the function $f$. $h \in H$ and $f \in H$, where $H$ is class of functions. Both $f$ and $h$ can be vectors. We select $h$ based on a training set, $\Xi$, of $m$ input vector examples. In Supervised leaning we know the values of $f$ for the $m$ samples in the training set $\Xi$. We assume that if we can find a hypothesis, $h$, that closely agrees with $f$ for the members of $\Xi$, then this hypothesis will be a good guess for $f$ when $\Xi$ is large. In Unsupervised learning, we simply have a training set of vectors without function values for them. The problem in this case, typically, is to partition the training set into subsets, $\Xi_1$,  ,$\Xi_R$, in some appropriate way.\cite{machineLearning}

Supervised algorithm such as One Class Support Vector Machine(One Class SVM)\cite{SVM} could be efficient to identify the anomalies in the data but it is process and memory intensive, so training the algorithm for each and every IP address is very costly in terms of resources. Because of the resource constraints of the router our approach is to first cluster the IP address based on the features using Unsupervised learning algorithms such as k-means and then apply One Class SVM on the clusters to decide on the boundaries of those clusters. Unsupervised algorithms are fast and consume less resource which make them good to be used on the devices which have less cpu power and less memory.

\subsubsection{Feature Scaling}

Before feeding data to learning algorithm, we have to do feature scaling, also called Standardizing. Feature scaling is done by removing the mean and scaling the feature to a unit variance value. It is necessary because of the fact that, different features which are at the different scales could cause one feature dominating other in the algorithm output result. e.g. consider two vectors (1, 2, 3000) (1, 3, 2000). If we calculate the Euclidean distance between these two vectors then it would be $(1-1)^2 + (2-3)^2 + (3000-2000)^2$ . Form this, it is evident that the larger term would dominate the result.

First we will convert training examples into a vector. Each row of the vector is one training example and each element in the vector is the feature. To standardize the input vector, mean and standard deviation is calculated for each feature in the input vector. Then new vector is created by subtracting the mean from every element of the feature vector and then dividing values of each feature vector by its standard deviation. The new vector created after this step is standardized vector, which is used as input to the learning algorithms.

\hspace{2cm} Standardization formula: $x' = \frac{x - \bar{x}}{\sigma}$

Where $x$ is the feature vector, ${\bar{x}}$ is the mean and $\sigma$  is its standard deviation.

\subsubsection{Clustering}

k-means clustering is one of the most efficient algorithm for creating clusters. The k-means problem is to find set of $K$ points $\{\mu_{1}, \mu_{2}, ..., \mu_{k}\}$ called centroids, where $\mu_{k}\in$ $\mathbb{R}^d$ and $K \in \mathbb{N}$, for training set $X = \{x^{1}, x^{2}, ..., x^{m}\}$, where $x^{i} \in \mathbb{R}^d$
and $i= {1,2, ..m}$ is a training example, such that the mean square distance from each training example $x^{i}$ of training set, to its nearest center $\mu_{k}$ ($argmin_{k} || x^{i} {-} \mu_{k} ||^{2}$), is minimum. $m \in \mathbb{N}$, are the number of training examples.\cite{kmeanClustering}

Lloyd's algorithm is most popular heuristic for k-means clustering, which we will be using for our analysis.

\begin{algorithm}
\caption{Lloyd's k-means algorithm}\label{kmeans}
\begin{algorithmic}
\State {Arbitrarily initialize $K$ cluster centroids $\mu_{1}, \mu_{2}, ..., \mu_{k}$}
\Repeat
  \For{$i\gets 1, m$}
    %\State {$c^{i}$ = index (from 1 to K) of cluster centroid closest to $x^{i}$}
    \State{$c^{i} = argmin_{k} || x^{i} {-} \mu_{k} ||^{2}$}\Comment{Cluster Assignment}
  \EndFor
  \For{$k\gets 1, K$}
    %\State {$\mu_{i}$ = average (mean) of points assigned to cluster k}
    \State{$\mu_{k} = \frac{1}{n} [x^{(k_{1})} + x^{(k_{2})} + ... + x^{(k_{n}})]$}\Comment{Move Centroid}
  \EndFor
\Until convergence
\end{algorithmic}
\end{algorithm}

For our thesis we will be using k-means++ algorithm\cite{k-means++} which is improvisation of kmeans, where arbitrarily initialization step is replaced by following simple, randomized seeding technique.

Let $D(x)$ denote the shortest distance from a data point to the closest center we have already chosen then following is the k-means++ algorithm.

\begin{algorithm}
\caption{kmeans++}\label{kmeans++}
\begin{algorithmic}[1]
  \State{Take one center $\mu_{1}$, chosen uniformly at random from $X$.}
  \State{Take a new center $\mu_{k}$ , choosing $x \in X$ with probability $\frac{D(x)^{2}}{\sum_{x \in X} D(x)^{2}}$}
  \State{Repeat Step 2. until we have taken $k$ centers altogether}
  \State{Proceed as with the Lloyd's k-means algorithm.}
\end{algorithmic}
\end{algorithm}

For our DDoS attack detection program, we will be using the Scikit-learn libraries. Scikit-learn is most popular and rich open source machine learning software library for the Python programming language and they have implementation for both kmeans and One Class SVM machine learning algorithms as well as data preprocessing programs.

We will be using training set in the format given in the figure \ref{table:feature} and we will be using k-means++ Scikit-learn library for clustering.

Before doing actual clustering we will first determine the number clusters and centroids\footnote{Centroids are the central vectors who presents the clusters.} Deciding on the number of clusters is important as randomly choosing the number of cluster will not be useful to have correct clustering. We will use Elbow method to find the optimal number of clusters. Elbow method check the percent of variance explained as function of the number of clusters. Following are the Eblow Diagrams for four samples.

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{elbow-method}
\caption{Elbow Method for cluster count detection} \label{fig:elbowmethod}
\end{figure}

Using the elbow method, variance for each cluster number is calculated and the cluster number which produce less variance for the next cluster number is selected as best choice of cluster number for the give sample data. To come up with the best clustering scheme for all the sample we have

To have correct clustering we first run the k-means algorithm to determine the central vectors called centroids. Clusters are represented by these centroids. As we have multiple samples (each sample has file associated with it), we will have cluster centroids for each sample. We will save all the centroids and then find the median of all the centroids removing the outliers so that we have good estimate of the correct centroids. This estimated centroids are used for clustering the samples. Following is the example of centroid vector where rows represents cluster label and columns represent the feature.

\begin{table}[H]
\centering
  \begin{tabular}{ l | c  c  c }
    Cluster      & ICMP  & TCP  & UDP \\
    \hline
    0         &{-0.16815612}       &{-0.14928111}    &{-0.16948046} \\
    1         &{-0.18181818}       &{5.13527652}     &{5.68956244} \\
    2         &{5.08663322}        &{-0.27110845}    &{-0.099885} \\
    3         &{-0.18670401}       &{-0.18804342}    &{-0.018538} \\
  \end{tabular}
\caption{k-means cluster centroids} \label{table:centroids}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.90\textwidth]{kemans-clustering}
\caption{Clustering using k-means++ algorithm} \label{fig:kmeans-clustering}
\end{figure}

To draw data points on 2 dimension space we had to reduce our 3 dimensional training example into 2 dimension without loosing much information. We have achieved this by using Principal-Component Analysis (PCA). PCA is a technique for taking a dataset consisting of a set of tuples representing points in a high-dimensional space and finding the directions along which the tuples line up best.\cite{pca}. We have used Scikit-learn PCA module for this purpose.

Using the centroids obtained in he previous step we will run kmeans++ algorithm and then test it for accuracy. kmean++ algorithm gives label to each training example. This label is the cluster number to which that training example has been assigned to. So our new labeled data look like following.

\begin{table}[H]
\centering
  \begin{tabular}{| l | c | c | c | c |}
    \hline
    {Destination IP Address}  &ICMP  &TCP &UDP  &Cluster \\
    \hline
    172.217.10.134  & 0     & 8     & 12  &1  \\ \hline
    65.19.96.252    & 5     & 0     & 192 &0  \\ \hline
    68.67.178.134   & 0     & 78    & 0   &2  \\ \hline
  \end{tabular}
\caption{Labeled Training Set (with cluster number)} \label{table:labeled-set}
\end{table}


We will run kmeans++ to for both training and testing set and we produce labeled data for both. We then checked how similar the test set clustering is with train set clustering. For measuring this similarity Rand Index(RI)\cite{ri-index} is used. RI is a measure of how many percent does the test clustering matches with our trained model.

\hspace{4cm} $RI={\frac {TP+TN}{TP+FP+FN+TN}}$

where $TP, TN, TN$ and $FN$ are the number of true positives, true negatives, false positives and false negatives respectively.

We have observed that with more number of training sets RI index improves.

Because of the reason that the training sets contain the flow information for different IP on a router during window of 300 seconds, there is very high possibility that same destination IP address is captured in multiple training set. Our goal it to find out the correct cluster for destination IP address so to achieve this goal we will check all the cluster assignment for a given destination IP address and we will select the cluster which has the highest occurring frequency among all the training sets selected for the clustering. We will also count the average number of packets going to a given IP address which will help us reduce the error in deciding the DDoS attack. We will save this labeling and cluster count information for each IP destination on the file system. This information tell us the normal behavior of the packets traveling from the router to a given destination. As we have fixed the centroids for the clustering algorithm, every time in the future we should expect the an IP address to be found in the same cluster if flow of packets for a given destination is as per our our previous knowledge. If there is a DDoS attack on a any destination with flooding, then we can expect to see that destination assigned different cluster.

But from the experiments on different data sets it is found that the destination under attack is labeled with the same cluster number when it was not under attack. This happened because there is no other cluster it can be assigned to so it gets assigned to cluster whoes centroid is nearest.

To avoid such conditions we will have to create boundaries for the clusters. This scheme will make sure that the attack will be detected even if destination is assigned to same cluster to which it was labeled when there was normal traffic for that destination.

for this we will be using One Class SVM which will help us to detect anomalies in the cluster. Compute and storage requirements of SVM increase rapidly with the number of training vectors, because of the fact that SVM is a quadratic programming problem (QP). So the approch presented in the paper is more efficient because the number of cluster are limited and always be far less than the number of destination IP address. Training one class SVM on clusters will be far less process and memory intensive than training on massive number of IP address.

For example the number of clusters we have create in our analysis are 4 in number while the number of IP address to which packets are flowing form router are 268 which is more than 60 times.

\subsubsection{Anomaly Detection using One Class Support-Vector Machine}

\subsubsection{Support-Vector Machine}

Support-Vector Machine is a supervised learning algorithm which tries to classify data. Classification is based on the label of the training set. Consider the training set $\{(x^{1},y^{1}),(x^{2},y^{2}), .., (x^{m},y^{m})\}$, where $x^{i} \in \mathbb{R}^d$ is the training example and $y^{i} \in \{-1, +1\}$ is the label which is the classification value for $x^{i}$,

SVM try to create non-linear separation boundary by projecting data points through a non-linear function $\phi$ to higher dimension space. The data points in space $I$ which can not be separated by a line are projected to the feature space $F$ where there can a hyperplane that separate data point of one class form another. If the hyperplane is projected back on original space $I$ the we get non-linear curve.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{SVM}
\caption{Linear Separation using Support Vector} \label{fig:SVM}
\end{figure}

The hyperplane is represented with the equation $w^{T}x + b = 0$, where $w \in F$ and $b \in R$. This hyperplane separated the training example labeled with $-1$ and $1$ into different classes. The position of the hyperplane is such that the distance from the closest point from each class to the hyperplane is same. To avoid the over-fitting, slack variables $\xi^{i}$ are introduced. Over-fitting happen because learned hypothesis fit training examples so well that it fails to generalize new examples. The constant $C > 0$ is the regularization parameter. If chosen large, we can avoid miss-classification of training examples. If chosen small, then we may miss classify few examples but margin would be large so that most of the points will be far away from the decision boundary. Thus SVM optimization problem is states as.\cite{SVM} \cite{svm-ml}

\begin{center}
  ${min}_{w,b,\xi^i} \ \frac{||w||^2}{2} + C \sum_{i=1}^m \xi^i$ \\
  $\mbox{ subject to: }$ \\
  $y^i( w^T \phi(x^i) + b) \geq 1 - \xi^i \mbox{ for all } i = 1, \dots, m$ \\
  \hspace{3cm} $\xi^i \geq 0 \mbox{ for all } i = 1, \dots, m$ \\
\end{center}

If this minimization problem is solved using Lagrange multipliers then the classification function $f(x)$ can be stated as.

\begin{center}
$f(x)=sgn(\sum_{i=1}^m \alpha^i y^i K(x,x^i) \ + b)$
\end{center}

$\alpha^i$ here are the Lagrange multipliers and $x^i$ with $\alpha^i$ are called the Support Vectors.

The function $K(x,xi)=\phi(x)^T \phi(xi)$ is known as the kernel function. It's responsible in projecting data points to the hyperplane.

\subsubsection{One Class Support-Vector Machine}

One Class Support-Vector Machine (One Class SVM) is the extension of SVM which detect boundaries of the training set so that every new training example will be classifies as belong to training set or not. It separate all the training set data point from feature space $F$ and maximizes the distance of hyperplane from $F$. This creates a binary function which returns +1 for the training example which fit in the trained set region otherwise it will return -1

The minimization function of One Class SVM is slightly different than the SVM. \cite{SVM}

\begin{center}
  ${min}_{w,\rho,\xi^i} \ \frac{||w||^2}{2} + \frac{1}{\nu n} \sum_{i=1}^m \xi^i - \rho$ \\
  $\mbox{ subject to: }$ \\
  $(w.\phi(x^i)) \geq \rho - \xi^i \mbox{ for all } i = 1, \dots, m$ \\
  \hspace{2cm} $\xi^i \geq 0 \mbox{ for all } i = 1, \dots, m$ \\
\end{center}

The new variable introduced $\nu$ in place of $C$ from previous SVM equation is used to set upper bound on outliers/anomalies and lower bound on the number of training examples.

We will be using Scikit-learn's `OneClassSVM' classifier to train our model. We will have to train model for each cluster such that the input vector to the classifier will be set of all the training examples belonging to same clusters. Thus, if we have four clusters then we will have four classifier. The input vector to the classier will be of the form shown in Table \ref{table:labeled-set}

\begin{figure}[H]
\centering
\includegraphics[width=0.80\textwidth]{one-class-SVM}
\caption{One Class SVM} \label{fig:one-class-SVM}
\end{figure}


\subsubsection{Detection}

By this stage, we have destination IP address labeled with cluster and the average number of packets during the flow. Also we have classifier models for each of the cluster.

To detect the attack we will continuously capture the flow in in specified interval (e.g. 300 seconds). We will transform the captured flow into test set. Test set is then be clustered using the already calculated centroids. If there is any destination IP address for which new cluster labeled assigned during clustering does not match with the already store cluster label then that destination address added to the suspect list. If new label matched with the old then the feature vector for that destination address is passed to the cluster classier to which it belongs and if the output of the classifier is -1 then then that destination is added to suspect list. For every destination from this compiled list we then calculate the number of packets observed in the captured sample. If there is significant difference between the number of capture packet in the past and in the present then that destination is recorded as DDos attack candidate because of the change in th behavior of the traffic.

<!-- Write own detection Algo here -->

Next task of the router then will be to communicate the destination network the change in the behavior of traffic observed at that router for a that destination. Destination network collect that information received from the routers to know the source of the attack. This information can be used to know the nature of the attack.

To Communicate the destination network about the change in behavior router can use the existing ICMP protocol. ICMP protocol has been used to provide feedback about problems in the communication environment. ICMP messages are sent in several situations:  for example 1) when a datagram cannot reach its destination. 2) when the gateway does not have the buffering capacity to forward a datagram. 3) when the gateway can direct the host to send traffic on a shorter route.\cite{icmp} Similarly we can use ICMP protocol to inform destination router about the change in the traffic. ICMP protocol has many unused type code (there can be 0-255 types but as of now only 0-41 are in use) available. We can create our own type to communicate the anomaly in the flow.

Depending on the type and severity of the situation destination host or network can decide whether or not to inform router to block the traffic coming from that router. We would let this decision to be taken at the destination network. There can be different parameter based on which network can decide blocking the flow, such as how many router have reported the change in traffic? Is the attack information coming from the region which never had traffic in the past?

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{router-network-communication}
\caption{Router Network Communication} \label{fig:router-network-communication}
\end{figure}


\section{Conclusion}

{Note: Following need more detailed explanation}
The benifit of this system is that if a destination detect DDoS attack it could identify the source attack routers and just can ask just to that router to hold on to the packets or descard but not to send them until further notices. This will allow legitimate traffic to come.

A novel way to identify and mitigate DDoS attack is discussed in the paper. With the advance of NVF(Network Virtual Functional) it would be easy to push the learning algorithms to the routers and thus making them efficient in detecting the attacks and then ICMP protocol can be used to communicate location and attack information in between the routers and network.

\bibliographystyle{unsrt}   % Unsorted order
\bibliography{biblo}       % expects file "biblo.bib"

\end{document}
